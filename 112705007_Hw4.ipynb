{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-12-14T13:45:21.032359Z",
     "iopub.status.busy": "2025-12-14T13:45:21.031835Z",
     "iopub.status.idle": "2025-12-14T13:45:28.271546Z",
     "shell.execute_reply": "2025-12-14T13:45:28.270879Z",
     "shell.execute_reply.started": "2025-12-14T13:45:21.032333Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['data']\n",
      "['unlabeled', 'test', 'train']\n"
     ]
    }
   ],
   "source": [
    "# This notebook was trained on Kaggle.\n",
    "# Paths may need to be adjusted when running locally.\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset, Subset\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from torchvision.models import efficientnet_b4, EfficientNet_B4_Weights\n",
    "\n",
    "# print(os.listdir(\"/kaggle/input/hw4-dataset\"))\n",
    "# print(os.listdir(\"/kaggle/input/hw4-dataset/data\"))\n",
    "\n",
    "DATA_ROOT = \"./data\"\n",
    "\n",
    "TRAIN_DIR = os.path.join(DATA_ROOT, \"train\")\n",
    "TEST_DIR = os.path.join(DATA_ROOT, \"test\")\n",
    "UNLABELED_DIR = os.path.join(DATA_ROOT, \"unlabeled\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T13:45:31.456061Z",
     "iopub.status.busy": "2025-12-14T13:45:31.455675Z",
     "iopub.status.idle": "2025-12-14T13:45:31.463306Z",
     "shell.execute_reply": "2025-12-14T13:45:31.462434Z",
     "shell.execute_reply.started": "2025-12-14T13:45:31.456040Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# train_transform = transforms.Compose([\n",
    "#     transforms.Resize((224, 224)),\n",
    "#     transforms.RandomHorizontalFlip(),\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize(\n",
    "#         mean=[0.485, 0.456, 0.406],\n",
    "#         std=[0.229, 0.224, 0.225]\n",
    "#     ),\n",
    "# ])\n",
    "\n",
    "# test_transform = transforms.Compose([\n",
    "#     transforms.Resize((224, 224)),\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize(\n",
    "#         mean=[0.485, 0.456, 0.406],\n",
    "#         std=[0.229, 0.224, 0.225]\n",
    "#     ),\n",
    "# ])\n",
    "\n",
    "from torchvision.models import efficientnet_b4, EfficientNet_B4_Weights\n",
    "\n",
    "weights = EfficientNet_B4_Weights.DEFAULT\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((380, 380)),\n",
    "    transforms.RandomResizedCrop(380, scale=(0.8, 1.0)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ColorJitter(0.2, 0.2, 0.2, 0.1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=weights.transforms().mean,\n",
    "        std=weights.transforms().std,\n",
    "    ),\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((380, 380)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=weights.transforms().mean,\n",
    "        std=weights.transforms().std,\n",
    "    ),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T13:45:34.112329Z",
     "iopub.status.busy": "2025-12-14T13:45:34.111797Z",
     "iopub.status.idle": "2025-12-14T13:45:34.800495Z",
     "shell.execute_reply": "2025-12-14T13:45:34.799915Z",
     "shell.execute_reply.started": "2025-12-14T13:45:34.112303Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class TrainDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.samples = []\n",
    "        self.transform = transform\n",
    "\n",
    "        for label, cls in enumerate([\"real\", \"generated\"]):\n",
    "            cls_dir = os.path.join(root_dir, cls)\n",
    "            for fname in os.listdir(cls_dir):\n",
    "                self.samples.append(\n",
    "                    (os.path.join(cls_dir, fname), label)\n",
    "                )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path, label = self.samples[idx]\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "\n",
    "# train_dataset = TrainDataset(TRAIN_DIR, train_transform)\n",
    "\n",
    "# # ÂèñÂæóÊâÄÊúâ index\n",
    "# all_indices = list(range(len(train_dataset)))\n",
    "\n",
    "# # Âàá 80% train / 20% val\n",
    "# train_idx, val_idx = train_test_split(\n",
    "#     all_indices,\n",
    "#     test_size=0.5,\n",
    "#     random_state=777,\n",
    "#     stratify=[label for _, label in train_dataset.samples]\n",
    "# )\n",
    "\n",
    "# train_subset = Subset(train_dataset, train_idx)\n",
    "# val_subset = Subset(train_dataset, val_idx)\n",
    "\n",
    "# train_loader = DataLoader(\n",
    "#     train_subset,\n",
    "#     batch_size=32,\n",
    "#     shuffle=True,\n",
    "#     num_workers=2\n",
    "# )\n",
    "\n",
    "# val_loader = DataLoader(\n",
    "#     val_subset,\n",
    "#     batch_size=32,\n",
    "#     shuffle=False,\n",
    "#     num_workers=2\n",
    "# )\n",
    "\n",
    "final_train_dataset = TrainDataset(TRAIN_DIR, train_transform)\n",
    "\n",
    "final_train_loader = DataLoader(\n",
    "    final_train_dataset,\n",
    "    batch_size=16,\n",
    "    shuffle=True,\n",
    "    num_workers=2\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T13:45:38.250660Z",
     "iopub.status.busy": "2025-12-14T13:45:38.250390Z",
     "iopub.status.idle": "2025-12-14T13:45:38.536222Z",
     "shell.execute_reply": "2025-12-14T13:45:38.535646Z",
     "shell.execute_reply.started": "2025-12-14T13:45:38.250641Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class TestDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.image_paths = [\n",
    "            os.path.join(root_dir, fname)\n",
    "            for fname in sorted(os.listdir(root_dir))\n",
    "        ]\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, os.path.basename(img_path)\n",
    "\n",
    "test_dataset = TestDataset(TEST_DIR, test_transform)\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=16,\n",
    "    shuffle=False,\n",
    "    num_workers=2\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T13:45:41.533834Z",
     "iopub.status.busy": "2025-12-14T13:45:41.533567Z",
     "iopub.status.idle": "2025-12-14T13:45:41.538075Z",
     "shell.execute_reply": "2025-12-14T13:45:41.537358Z",
     "shell.execute_reply.started": "2025-12-14T13:45:41.533813Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "tta_transform = transforms.Compose([\n",
    "    transforms.Resize((380, 380)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=weights.transforms().mean,\n",
    "        std=weights.transforms().std,\n",
    "    ),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T13:45:43.795845Z",
     "iopub.status.busy": "2025-12-14T13:45:43.795571Z",
     "iopub.status.idle": "2025-12-14T13:45:43.823735Z",
     "shell.execute_reply": "2025-12-14T13:45:43.823209Z",
     "shell.execute_reply.started": "2025-12-14T13:45:43.795825Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class TTADataset(Dataset):\n",
    "    def __init__(self, root_dir, transform):\n",
    "        self.image_paths = [\n",
    "            os.path.join(root_dir, fname)\n",
    "            for fname in sorted(os.listdir(root_dir))\n",
    "        ]\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        image = self.transform(image)\n",
    "        return image, os.path.basename(img_path)\n",
    "\n",
    "tta_dataset = TTADataset(TEST_DIR, tta_transform)\n",
    "\n",
    "tta_loader = DataLoader(\n",
    "    tta_dataset,\n",
    "    batch_size=16,\n",
    "    shuffle=False,\n",
    "    num_workers=2\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T13:46:21.071841Z",
     "iopub.status.busy": "2025-12-14T13:46:21.071026Z",
     "iopub.status.idle": "2025-12-14T13:46:21.100463Z",
     "shell.execute_reply": "2025-12-14T13:46:21.099927Z",
     "shell.execute_reply.started": "2025-12-14T13:46:21.071806Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class UnlabeledDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.image_paths = []\n",
    "        self.transform = transform\n",
    "\n",
    "        for fname in os.listdir(root_dir):\n",
    "            self.image_paths.append(os.path.join(root_dir, fname))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, img_path\n",
    "\n",
    "unlabeled_dataset = UnlabeledDataset(UNLABELED_DIR, test_transform)\n",
    "\n",
    "unlabeled_loader = DataLoader(\n",
    "    unlabeled_dataset,\n",
    "    batch_size=16,\n",
    "    shuffle=False,\n",
    "    num_workers=2\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T13:46:23.154996Z",
     "iopub.status.busy": "2025-12-14T13:46:23.154240Z",
     "iopub.status.idle": "2025-12-14T13:46:24.455530Z",
     "shell.execute_reply": "2025-12-14T13:46:24.454891Z",
     "shell.execute_reply.started": "2025-12-14T13:46:23.154970Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/efficientnet_b4_rwightman-23ab8bcd.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_b4_rwightman-23ab8bcd.pth\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 74.5M/74.5M [00:00<00:00, 162MB/s] \n"
     ]
    }
   ],
   "source": [
    "# from torchvision.models import resnet18, ResNet18_Weights\n",
    "\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# model = resnet18(weights=ResNet18_Weights.DEFAULT)\n",
    "\n",
    "# for param in model.parameters():\n",
    "#     param.requires_grad = False\n",
    "\n",
    "# for name, param in model.named_parameters():\n",
    "#     if \"layer4\" in name:\n",
    "#         param.requires_grad = True\n",
    "\n",
    "# # classifier\n",
    "# model.fc = nn.Linear(model.fc.in_features, 2)\n",
    "# for param in model.fc.parameters():\n",
    "#     param.requires_grad = True\n",
    "\n",
    "# model = model.to(device)\n",
    "from torchvision.models import efficientnet_b4, EfficientNet_B4_Weights\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "weights = EfficientNet_B4_Weights.DEFAULT\n",
    "model = efficientnet_b4(weights=weights)\n",
    "\n",
    "# Freeze all\n",
    "for p in model.parameters():\n",
    "    p.requires_grad = False\n",
    "\n",
    "# Unfreeze last block\n",
    "for name, p in model.named_parameters():\n",
    "    if \"features.7\" in name:\n",
    "        p.requires_grad = True\n",
    "\n",
    "# Replace classifier\n",
    "model.classifier[1] = nn.Linear(model.classifier[1].in_features, 2)\n",
    "for p in model.classifier.parameters():\n",
    "    p.requires_grad = True\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T13:46:29.844163Z",
     "iopub.status.busy": "2025-12-14T13:46:29.843616Z",
     "iopub.status.idle": "2025-12-14T13:46:29.849979Z",
     "shell.execute_reply": "2025-12-14T13:46:29.849235Z",
     "shell.execute_reply.started": "2025-12-14T13:46:29.844140Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "criterion_train = nn.CrossEntropyLoss()   # È†êË®≠ reduction=\"mean\"\n",
    "criterion_mixed = nn.CrossEntropyLoss(reduction=\"none\")\n",
    "\n",
    "optimizer = torch.optim.AdamW([\n",
    "    {\"params\": model.features.parameters(), \"lr\": 1e-5},\n",
    "    {\"params\": model.classifier.parameters(), \"lr\": 3e-4},\n",
    "], weight_decay=1e-4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T13:46:39.583306Z",
     "iopub.status.busy": "2025-12-14T13:46:39.583039Z",
     "iopub.status.idle": "2025-12-14T13:46:39.588102Z",
     "shell.execute_reply": "2025-12-14T13:46:39.587423Z",
     "shell.execute_reply.started": "2025-12-14T13:46:39.583286Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def train_one_epoch(model, loader):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for imgs, labels in loader:\n",
    "        imgs = imgs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(imgs)\n",
    "        loss = criterion_train(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    return total_loss / len(loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T13:46:42.213410Z",
     "iopub.status.busy": "2025-12-14T13:46:42.213119Z",
     "iopub.status.idle": "2025-12-14T13:46:42.218348Z",
     "shell.execute_reply": "2025-12-14T13:46:42.217672Z",
     "shell.execute_reply.started": "2025-12-14T13:46:42.213358Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in loader:\n",
    "            imgs = imgs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(imgs)\n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    f1 = f1_score(all_labels, all_preds)\n",
    "    return f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T13:46:47.325182Z",
     "iopub.status.busy": "2025-12-14T13:46:47.324631Z",
     "iopub.status.idle": "2025-12-14T14:44:12.455971Z",
     "shell.execute_reply": "2025-12-14T14:44:12.455098Z",
     "shell.execute_reply.started": "2025-12-14T13:46:47.325159Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5] Loss: 0.3732\n",
      "Epoch [2/5] Loss: 0.2306\n",
      "Epoch [3/5] Loss: 0.1971\n",
      "Epoch [4/5] Loss: 0.1784\n",
      "Epoch [5/5] Loss: 0.1643\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 5\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    loss = train_one_epoch(model, final_train_loader)\n",
    "    print(f\"Epoch [{epoch+1}/{EPOCHS}] Loss: {loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T14:45:08.062785Z",
     "iopub.status.busy": "2025-12-14T14:45:08.062491Z",
     "iopub.status.idle": "2025-12-14T14:49:23.508564Z",
     "shell.execute_reply": "2025-12-14T14:49:23.507731Z",
     "shell.execute_reply.started": "2025-12-14T14:45:08.062760Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pseudo-labeled samples: 10661\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "model.eval()\n",
    "pseudo_samples = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for imgs, paths in unlabeled_loader:\n",
    "        imgs = imgs.to(device)\n",
    "        outputs = model(imgs)\n",
    "        probs = F.softmax(outputs, dim=1)\n",
    "\n",
    "        for prob, path in zip(probs.cpu().numpy(), paths):\n",
    "            conf = prob.max()\n",
    "            label = prob.argmax()\n",
    "\n",
    "            if prob[1] >= 0.99: \n",
    "                pseudo_samples.append((path, 1))\n",
    "            elif prob[0] >= 0.985: \n",
    "                pseudo_samples.append((path, 0))\n",
    "\n",
    "print(\"Pseudo-labeled samples:\", len(pseudo_samples))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T14:49:46.363299Z",
     "iopub.status.busy": "2025-12-14T14:49:46.362722Z",
     "iopub.status.idle": "2025-12-14T14:49:46.380697Z",
     "shell.execute_reply": "2025-12-14T14:49:46.380058Z",
     "shell.execute_reply.started": "2025-12-14T14:49:46.363268Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# class MixedDataset(Dataset):\n",
    "#     def __init__(self, original_dataset, pseudo_samples, transform):\n",
    "#         self.samples = list(original_dataset.samples)\n",
    "#         self.samples.extend(pseudo_samples)\n",
    "#         self.transform = transform\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.samples)\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         img_path, label = self.samples[idx]\n",
    "#         image = Image.open(img_path).convert(\"RGB\")\n",
    "#         if self.transform:\n",
    "#             image = self.transform(image)\n",
    "#         return image, label\n",
    "\n",
    "class MixedDataset(Dataset):\n",
    "    def __init__(self, real_dataset, pseudo_samples, transform):\n",
    "        self.samples = []\n",
    "        self.transform = transform\n",
    "\n",
    "        # real samples\n",
    "        for path, label in real_dataset.samples:\n",
    "            self.samples.append((path, label, 0))  # is_pseudo = 0\n",
    "\n",
    "        # pseudo samples\n",
    "        for path, label in pseudo_samples:\n",
    "            self.samples.append((path, label, 1))  # is_pseudo = 1\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path, label, is_pseudo = self.samples[idx]\n",
    "        image = Image.open(path).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label, is_pseudo\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "        \n",
    "mixed_dataset = MixedDataset(\n",
    "    final_train_dataset,\n",
    "    pseudo_samples,\n",
    "    train_transform\n",
    ")\n",
    "\n",
    "mixed_loader = DataLoader(\n",
    "    mixed_dataset,\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    num_workers=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T14:49:49.693056Z",
     "iopub.status.busy": "2025-12-14T14:49:49.692406Z",
     "iopub.status.idle": "2025-12-14T14:49:49.698441Z",
     "shell.execute_reply": "2025-12-14T14:49:49.697610Z",
     "shell.execute_reply.started": "2025-12-14T14:49:49.693034Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def train_one_epoch_mixed(model, loader):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for imgs, labels, is_pseudo in loader:\n",
    "        imgs = imgs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        is_pseudo = is_pseudo.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(imgs)\n",
    "\n",
    "        # --------- üî• ‰Ω†ÂïèÁöÑÈáçÈªûÔºöÂ∞±Âú®ÈÄôË£° üî• ---------\n",
    "        loss_all = criterion_mixed(outputs, labels)   # (B,)\n",
    "\n",
    "        # class-level weight\n",
    "        class_weights = torch.ones_like(loss_all)\n",
    "        class_weights[labels == 0] = 1.1\n",
    "        class_weights[labels == 1] = 0.9\n",
    "\n",
    "        # pseudo-label weight\n",
    "        pseudo_weights = torch.ones_like(loss_all)\n",
    "        pseudo_weights[is_pseudo == 1] = 0.5\n",
    "\n",
    "        # combined weight\n",
    "        weights = class_weights * pseudo_weights\n",
    "\n",
    "        loss = (loss_all * weights).mean()\n",
    "        # -----------------------------------------------\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    return total_loss / len(loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T14:49:52.850515Z",
     "iopub.status.busy": "2025-12-14T14:49:52.850221Z",
     "iopub.status.idle": "2025-12-14T15:32:37.595852Z",
     "shell.execute_reply": "2025-12-14T15:32:37.594907Z",
     "shell.execute_reply.started": "2025-12-14T14:49:52.850492Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Final] Epoch [1/3] Loss: 0.1125\n",
      "[Final] Epoch [2/3] Loss: 0.1072\n",
      "[Final] Epoch [3/3] Loss: 0.1024\n"
     ]
    }
   ],
   "source": [
    "FINAL_EPOCHS = 3\n",
    "\n",
    "for epoch in range(FINAL_EPOCHS):\n",
    "    loss = train_one_epoch_mixed(model, mixed_loader)\n",
    "    print(f\"[Final] Epoch [{epoch+1}/{FINAL_EPOCHS}] Loss: {loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T15:35:18.834475Z",
     "iopub.status.busy": "2025-12-14T15:35:18.833803Z",
     "iopub.status.idle": "2025-12-14T15:38:31.443296Z",
     "shell.execute_reply": "2025-12-14T15:38:31.442527Z",
     "shell.execute_reply.started": "2025-12-14T15:35:18.834445Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# model.eval()\n",
    "\n",
    "# test_ids = []\n",
    "# test_preds = []\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     for imgs, img_names in test_loader:\n",
    "#         imgs = imgs.to(device)\n",
    "\n",
    "#         outputs = model(imgs)\n",
    "#         preds = torch.argmax(outputs, dim=1)\n",
    "\n",
    "#         test_preds.extend(preds.cpu().numpy())\n",
    "\n",
    "#         test_ids.extend([\n",
    "#             os.path.splitext(name)[0] for name in img_names\n",
    "#         ])\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "model.eval()\n",
    "\n",
    "test_ids = []\n",
    "test_preds = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for imgs, img_names in tta_loader:\n",
    "        imgs = imgs.to(device)\n",
    "\n",
    "        outputs = model(imgs)\n",
    "        preds = torch.argmax(outputs, dim=1)\n",
    "\n",
    "        test_preds.extend(preds.cpu().numpy())\n",
    "        test_ids.extend([\n",
    "            os.path.splitext(name)[0] for name in img_names\n",
    "        ])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T15:39:02.122089Z",
     "iopub.status.busy": "2025-12-14T15:39:02.121300Z",
     "iopub.status.idle": "2025-12-14T15:39:02.203926Z",
     "shell.execute_reply": "2025-12-14T15:39:02.203338Z",
     "shell.execute_reply.started": "2025-12-14T15:39:02.122058Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "submission.csv saved!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000295da5dca4af09d5593174e15bb09</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00040d088f054d379b1aae48e9f425d2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0004501ec7a74f0ab1bed517e5fe4ee3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00135256c4e24a458efa66a398d45325</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00141c6d45b749b081b1881feba863c1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           filename  label\n",
       "0  000295da5dca4af09d5593174e15bb09      0\n",
       "1  00040d088f054d379b1aae48e9f425d2      1\n",
       "2  0004501ec7a74f0ab1bed517e5fe4ee3      0\n",
       "3  00135256c4e24a458efa66a398d45325      1\n",
       "4  00141c6d45b749b081b1881feba863c1      1"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.DataFrame({\n",
    "    \"filename\": test_ids,\n",
    "    \"label\": test_preds\n",
    "})\n",
    "\n",
    "submission.to_csv(\"submission.csv\", index=False)\n",
    "print(\"submission.csv saved!\")\n",
    "\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T15:40:02.554225Z",
     "iopub.status.busy": "2025-12-14T15:40:02.553628Z",
     "iopub.status.idle": "2025-12-14T15:40:02.695987Z",
     "shell.execute_reply": "2025-12-14T15:40:02.695417Z",
     "shell.execute_reply.started": "2025-12-14T15:40:02.554199Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"112705007_weight.pth\")\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 9001193,
     "sourceId": 14127264,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31193,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
